#    don't need this configuration, promtail should run on all nodes so that it is able to aggregate logs from them 
# tolerations:
#   - key: "workload"
#     operator: "Equal"
#     value: "monitoring"
#     effect: "NoSchedule"

# nodeSelector:
#   workload: monitoring

config:
  lokiAddress: http://loki-gateway.monitoring.svc.cluster.local/loki/api/v1/push

  snippets:
    extraScrapeConfigs: |
      - job_name: static-varlogs
        static_configs:
          - targets:
              - localhost
            labels:
              job: varlogs
              __path__: /var/log/containers/*.log
      - job_name: k8s-pod-logs
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: container
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_node_name]
            target_label: node
          - action: replace
            source_labels: [__meta_kubernetes_pod_uid]
            target_label: __path__
            replacement: /var/log/pods/*/$1/*.log


    extraRelabelConfigs:
      - source_labels: [__meta_kubernetes_pod_node_name]
        target_label: __host__
      - source_labels: [__meta_kubernetes_namespace]
        regex: default
        action: keep

    # Reduce verbosity
    client:
      backoff_config:
        max_period: 5s
        max_retries: 3

# Tell Promtail to watch pod logs in Kubernetes
extraVolumes:
  - name: varlog
    hostPath:
      path: /var/log

# Mount the volumes that promtail is scraping 
extraVolumeMounts:
  - name: varlog
    mountPath: /var/log
    readOnly: true

# Run as DaemonSet on all nodes
daemonset:
  enabled: true

# ServiceMonitor to let Prometheus scrape Promtail metrics
serviceMonitor:
  enabled: true
  labels:
    release: kube-prometheus-stack
