---
- name: Deploy full Kubernetes stack to AWS using Ansible
  hosts: localhost
  connection: local
  gather_facts: False
  vars_prompt:
    - name: email
      prompt: "We need your email to set up the SNS service, it won't go anywhere"
      private: False
      default: "idanzigm@gmail.com"
    - name: aws_id
      prompt: "We also need your AWS ID to set up everything, it won't go anywhere"
      private: False
      default: "109798190983"
    - name: openai_secret_arn
      prompt: "Enter the ARN for your secret containing your open AI API key (you need to purchase credits on OpenAI for the integration to work, 2$ is more than enough for a demo)"
      private: False
      default: "arn:aws:secretsmanager:us-east-1:109798190983:secret:openai-key-NSazkz"
  vars:
    cluster_name: "doggy-app-eks-cluster-0"
    nodegroup_name: "doggy-app-eks-ng-monitoring"
    region: "us-east-1"
    config_dir: "/home/ec2-user/config"
    arch_dir: "/home/ec2-user/kubernetesArchitecture/kubernetes"


#######################################################################
  tasks:

    - name: set up environment 
      block: 
        - name: Ensure /home/ec2-user/config directory exists
          file:
            path: "/home/ec2-user/config"
            state: directory
            mode: '0755'

# this should be done with AWS Module 
        - name: Update kubeconfig
          shell: aws eks update-kubeconfig --region {{ region }} --name {{ cluster_name }} --profile eks-cluster-admin

# is there an eks module 
        - name: Associate IAM OIDC provider
          shell: eksctl utils associate-iam-oidc-provider --cluster {{ cluster_name }} --approve

#AWS Module 
        - name: Get OIDC URL
          shell: |
            aws eks describe-cluster \
              --name {{ cluster_name }} \
              --query "cluster.identity.oidc.issuer" \
              --output text | sed 's|https://||'
          register: oidc_url

        - name: Create ingress namespace
          kubernetes.core.k8s:
            name: ingress-nginx
            api_version: v1
            kind: Namespace
            state: present

        - name: Create monitoring namespace
          kubernetes.core.k8s:
            name: monitoring
            api_version: v1
            kind: Namespace
            state: present

#This should be done with Kube module 
        - name: Install Helm
          shell: curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

        - name: Apply ingress 
          shell: kubectl apply -k "{{ arch_dir }}/ingress/"
          async: 300 
          poll: 0 
          register: deploying_ingress 


#########################################################################
############# Template CloudFormation First Batch ########################

    - name: Create the CloudFormation templates 
      block: 
        - name: Render the autoscaler role YAML
          shell: |
            envsubst < "{{ arch_dir }}/autoscaler/cf-autoscaler-role.yaml" > "{{ config_dir }}/cf-autoscaler-role-up.yaml"
          environment:
            OIDC_URL: "{{ oidc_url.stdout }}"
            AWS_ID: "{{ aws_id }}"

        - name: Render the SNS stack yaml 
          shell: |
            envsubst < "{{ arch_dir }}/monitoring/alerting/cf-sns.yaml" > "{{ config_dir }}/cf-sns-up.yaml"
          environment: 
            EMAIL: "{{ email }}"




#########################################################################
############# Deploy CloudFormation First Batch ########################

    - name: Deploy the Autoscaler role and SNS 
      block: 

        - name: Deploy autoscaler role with CloudFormation
          amazon.aws.cloudformation:
            stack_name: cluster-autoscaler-iam-role
            template_body: "{{ lookup('file', config_dir + '/cf-autoscaler-role-up.yaml') }}"
            state: present
            capabilities:
              - CAPABILITY_NAMED_IAM
          register: deploying_autoscaler_stack
          async: 300 
          poll: 0 

# Use AWS Module 
        - name: Deploy SNS 
          amazon.aws.cloudformation:
            stack_name: sns-doggy
            template_body: "{{ lookup('file', config_dir + '/cf-sns-up.yaml') }}"
            state: present
          register: deploying_sns_stack
          async: 300 
          poll: 0 

##########################################################
########### INSTALL REPOSITORIES ########################


    - name: Install Repos 
      block: 
        - name: Add autoscaler Helm repo
          kubernetes.core.helm_repository:
            name: autoscaler
            repo_url: https://kubernetes.github.io/autoscaler
          register: installing_autoscaler_repo

# Do i need helm_repository to do this? 
        - name: Add Prometheus Helm repo
          kubernetes.core.helm_repository:
            name: prometheus-stack
            repo_url: https://prometheus-community.github.io/helm-charts
          register: installing_prometheus_repo

# do i need helm_repository to do this 
        - name: Add Grafana Helm repo
          kubernetes.core.helm_repository:
            name: Grafan
            repo_url: https://grafana.github.io/helm-charts
          register: installing_grafana_repo



###############################################################
############### INSTALL STACK ################################

    - name: Deploy Repos 
      block: 
# does this work 
        - name: Deploy Prometheus stack
          kubernetes.core.helm:
            name: kube-prometheus-stack
            chart_ref: prometheus-community/kube-prometheus-stack
            release_namespace: monitoring
            create_namespace: true
            values_files:
              - "{{ arch_dir }}/monitoring/prometheus/prometheus-values.yaml"
          register: deploying_prometheus 

# Does this work 
        - name: deploying Loki stack
          kubernetes.core.helm:
            name: loki
            chart_ref: grafana/loki
            release_namespace: monitoring
            create_namespace: true
            values_files:
              - "{{ arch_dir }}/monitoring/loki/loki-values.yaml"
          register: deploying_loki

# Does this work 
        - name: Deploying Promtail stack
          kubernetes.core.helm:
            name: promtail
            chart_ref: grafana/promtail
            release_namespace: monitoring
            create_namespace: true
            values_files:
              - "{{ arch_dir }}/monitoring/promtail/promtail-values.yaml"
          register: deploying_promtail



############## WAIT #########################################

    - name: Wait for deployment 
      block:

        - name: Wait for autoscaler role to deploy
          async_status:
            jid: "{{ deploying_autoscaler_stack.ansible_job_id }}"
          register: deploying_autoscaler_stack_status
          until: deploying_autoscaler_stack.finished
          retries: 60
          delay: 5

        - name: Wait for sns to deploy ######
          async_status:
            jid: "{{ deploying_sns_stack.ansible_job_id }}"
          register: deploying_sns_stack_status
          until: deploying_sns_stack.finished
          retries: 60
          delay: 5


#########################################################################
############# Template CloudFormation Second Batch ########################

    - name: Create the second batch of templates 
      block: 

        - name: Get autoscaler role ARN
          shell: |
            aws cloudformation describe-stacks \
              --stack-name cluster-autoscaler-iam-role \
              --query "Stacks[0].Outputs[?OutputKey=='ClusterAutoscalerRoleArn'].OutputValue" \
              --output text
          register: autoscaler_role_arn
          when: deploying_autoscaler_stack.finished

        - name: Template the autoscaler values
          template:
            src: "{{ arch_dir }}/autoscaler/autoscaler-values.yaml.j2"
            dest: "{{ config_dir }}/autoscaler-values-up.yaml"
          register: autoscaler_template


# do i need an AWS module for this 
        - name: Return SNS ARN 
          shell: |
            aws cloudformation describe-stacks --stack-name sns-and-secret-doggy --query "Stacks[0].Outputs[?OutputKey=='SNSTopicArn'].OutputValue" --output text
          register: sns_topic_arn

        - name: Render alert hook role yaml 
          shell: |
            envsubst < "{{ arch_dir }}/monitoring/alerting/cf-alert-hook-role.yaml" > "{{ config_dir }}/cf-alert-hook-role-up.yaml"
          environment: 
            AWS_ID: "{{ aws_id }}"
            OIDC_URL: "{{ oidc_url.stdout }}"
            OPENAI_SECRET_ARN: "{{ openai_secret_arn }}"
            SNS_TOPIC_ARN: "{{ sns_topic_arn }}"

#########################################################################
############# Deploy Second Batch ########################

    - name: Deploy the autoscaler and the alert-role
      block:  

        - name: Install cluster autoscaler via Helm
          kubernetes.core.helm:
            name: cluster-autoscaler
            chart_ref: autoscaler/cluster-autoscaler
            release_namespace: kube-system
            create_namespace: true
            values_files:
              - "{{ config_dir }}/autoscaler-values-up.yaml"
            state: present
          async: 300 
          poll: 0 

        - name:  Deploy alert hook IAM role
          amazon.aws.cloudformation:
            stack_name: alert-hook-iam-role
            template_body: "{{ lookup('file', config_dir + '/cf-alert-hook-role-up.yaml') }}"
            state: present
          register: deploying_aler_stack


    - name: Deploy the alert hook
      block:  

        - name: Apply Loki alert rules
          shell: kubectl apply -f "{{ arch_dir }}/monitoring/loki/loki-alert-rules.yaml" -n monitoring

#AWS module 
        - name: Get alert hook role ARN
          shell: |
            aws cloudformation describe-stacks \
              --stack-name alert-hook-iam-role \
              --query "Stacks[0].Outputs[?OutputKey=='ClusterAlerterRoleArn'].OutputValue" \
              --output text
          register: alerter_role_arn

        - name: Render alert service account
          template:
            src: "{{ arch_dir }}/monitoring/alerting/alert-service-account.yaml.j2"
            dest: "{{ config_dir }}/alert-service-account-up.yaml"

        - name: Apply alert service account
          kubernetes.core.k8s:
            state: present
            src: "{{ config_dir }}/alert-service-account-up.yaml"
            apply: True 

        - name: Render alert pod
          template:
            src: "{{ arch_dir }}/monitoring/alerting/alert-pod.yaml.j2"
            dest: "{{ config_dir }}/alert-pod-up.yaml"


        - name: Apply alert service account
          kubernetes.core.k8s:
            state: present
            src: "{{ config_dir }}/alert-pod-up.yaml"
            apply: True 


 #################################################################
 ######################### DEPLOY PODS ##################################

    - name: Deploy pods 
      block:  
        - name: Wait for ingress to deploy 
          async_status:
            jid: "{{ deploying_ingress.ansible_job_id }}"
          register: deploying_ingress_status
          until: deploying_ingress.finished
          retries: 60
          delay: 5

        - name: Get LoadBalancer hostname
          shell: |
            kubectl get ingress doggy-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
          register: lb_host

        - name: Create frontend config map
          shell: |
            kubectl create configmap frontend-config \
              --from-literal=LOAD_BALANCER_URL=http://{{ lb_host.stdout }} \
              --dry-run=client -o yaml | kubectl apply -f -

        - name: Apply alert service account
          kubernetes.core.k8s:
            state: present
            src: "{{ arch_dir }}/default/pods.yaml"
            apply: True 

        - name: Apply alert service account
          kubernetes.core.k8s:
            state: present
            src: "{{ arch_dir }}/default/services.yaml"
            apply: True 

...
